{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Statistics - Project\n",
    "\n",
    "Course: HDip in Computing in Data Analytics <br>\n",
    "Module: Applied Statistics <br>\n",
    "Lecturer: Ian McLoughlin <br>\n",
    " \n",
    "A notebook which contains the work on the project for the above module (Sept 2024).\n",
    "\n",
    "Student: Eilis Donohue (G00006088)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- Project Description\n",
    "- Dataset Description\n",
    "- $t$-test\n",
    "- ANOVA test\n",
    "- Further Tests\n",
    "- References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Description\n",
    "In this project, you will analyze the [PlantGrowth R dataset](https://vincentarelbundock.github.io/Rdatasets/csv/datasets/PlantGrowth.csv).\n",
    "You will find [a short description](https://vincentarelbundock.github.io/Rdatasets/doc/datasets/PlantGrowth.html) of it on [Vicent Arel-Bundock's Rdatasets page](https://vincentarelbundock.github.io/Rdatasets/).\n",
    "The dataset contains two main variables, a treatment group and the weight of plants within those groups.\n",
    "\n",
    "Your task is to perform t-tests and ANOVA on this dataset while describing the dataset and explaining your work.\n",
    "In doing this you should:\n",
    "\n",
    "1. Download and save the dataset to your repository.\n",
    "\n",
    "2. Describe the data set in your notebook.\n",
    "\n",
    "3. Describe what a t-test is, how it works, and what the assumptions are.\n",
    "\n",
    "3. Perform a t-test to determine whether there is a significant difference between the two treatment groups `trt1` and `trt2`.\n",
    "\n",
    "4. Perform ANOVA to determine whether there is a significant difference between the three treatment groups `ctrl`, `trt1`, and `trt2`.\n",
    "\n",
    "5. Explain why it is more appropriate to apply ANOVA rather than several t-tests when analyzing more than two groups.\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required python packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "# To perform a power calculation\n",
    "from statsmodels.stats.power import FTestAnovaPower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rownames</th>\n",
       "      <th>weight</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4.17</td>\n",
       "      <td>ctrl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5.58</td>\n",
       "      <td>ctrl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5.18</td>\n",
       "      <td>ctrl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6.11</td>\n",
       "      <td>ctrl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4.50</td>\n",
       "      <td>ctrl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rownames  weight group\n",
       "0         1    4.17  ctrl\n",
       "1         2    5.58  ctrl\n",
       "2         3    5.18  ctrl\n",
       "3         4    6.11  ctrl\n",
       "4         5    4.50  ctrl"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data and display first 5 rows\n",
    "data = pd.read_csv('data/plant_growth.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ctrl' 'trt1' 'trt2']\n"
     ]
    }
   ],
   "source": [
    "# Get the unique group names from the group column\n",
    "group_names = data[\"group\"].unique()  \n",
    "print(group_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30 entries, 0 to 29\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   rownames  30 non-null     int64  \n",
      " 1   weight    30 non-null     float64\n",
      " 2   group     30 non-null     object \n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 852.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# Show the dtype and number of observations including nulls\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Description\n",
    " - The dataset has 30 samples with 3 features: Rownames (numeric), Weight (numeric) and group(string).\n",
    " - The rowname appears as a sequential index feature and will not be of use for statistical analysis.\n",
    " - The group feature is a categorical variable (nominal) with 3 unique values: 'ctrl', 'trt1' and 'trt2'. From the dataset description, it is understood that these represent a control and two different treatment conditions [2].\n",
    " - The weight feature represents the plant weight and is a continuous variable (ratio) which is quantitative numeric and will be used for statistical analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the weight data for each group\n",
    "for item in group_names:\n",
    "    # Extract the data related to one group\n",
    "    weight_data = data[data[\"group\"] == item].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.17</td>\n",
       "      <td>ctrl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.58</td>\n",
       "      <td>ctrl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.18</td>\n",
       "      <td>ctrl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.11</td>\n",
       "      <td>ctrl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.50</td>\n",
       "      <td>ctrl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weight group\n",
       "0    4.17  ctrl\n",
       "1    5.58  ctrl\n",
       "2    5.18  ctrl\n",
       "3    6.11  ctrl\n",
       "4    4.50  ctrl"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rownmames columns\n",
    "weight_data = data.drop(columns='rownames')\n",
    "weight_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the weight column for some statistical analysis\n",
    "weight_data.drop(columns = \"group\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entire dataset statistics: \n",
      "        weight\n",
      "count   30.00\n",
      "mean     5.07\n",
      "std      0.70\n",
      "min      3.59\n",
      "25%      4.55\n",
      "50%      5.15\n",
      "75%      5.53\n",
      "max      6.31 \n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Display the basic statistics of the overall dataset and each group\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEntire dataset statistics: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweight_data\u001b[38;5;241m.\u001b[39mdescribe()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGroup statistics: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweight_data\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgroup\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdescribe()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\eilis.donohue\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:9183\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   9180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   9181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 9183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[0;32m   9184\u001b[0m     obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   9185\u001b[0m     keys\u001b[38;5;241m=\u001b[39mby,\n\u001b[0;32m   9186\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   9187\u001b[0m     level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   9188\u001b[0m     as_index\u001b[38;5;241m=\u001b[39mas_index,\n\u001b[0;32m   9189\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m   9190\u001b[0m     group_keys\u001b[38;5;241m=\u001b[39mgroup_keys,\n\u001b[0;32m   9191\u001b[0m     observed\u001b[38;5;241m=\u001b[39mobserved,\n\u001b[0;32m   9192\u001b[0m     dropna\u001b[38;5;241m=\u001b[39mdropna,\n\u001b[0;32m   9193\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\eilis.donohue\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1329\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1329\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m get_grouper(\n\u001b[0;32m   1330\u001b[0m         obj,\n\u001b[0;32m   1331\u001b[0m         keys,\n\u001b[0;32m   1332\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   1333\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   1334\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m   1335\u001b[0m         observed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default \u001b[38;5;28;01melse\u001b[39;00m observed,\n\u001b[0;32m   1336\u001b[0m         dropna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna,\n\u001b[0;32m   1337\u001b[0m     )\n\u001b[0;32m   1339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[0;32m   1340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[1;32mc:\\Users\\eilis.donohue\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\grouper.py:1043\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[0;32m   1041\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1043\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1045\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'group'"
     ]
    }
   ],
   "source": [
    "# Get the basic statistical measures of the dataset \n",
    "# Set the pandas table float format\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "# Display the basic statistics of the overall dataset and each group\n",
    "print(f'Entire dataset statistics: \\n {weight_data.describe()} \\n')\n",
    "print(f'Group statistics: \\n {weight_data.groupby('group').describe()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn boxplot\n",
    "sns.boxplot(x='group', y='weight', data=data, whis=1.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Seaborn histograms\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "sns.histplot(data=data, x='weight', hue='group', bins=5, kde=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shapiro-Wilk Test\n",
    "\n",
    "The Shapiro-Wilk test is a test of normality. The null hypothesis of the test is that the data is normally distributed. It is useful to verify the assumption of normality given the small sample size for each group.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapiro wilk test for normality on each group\n",
    "print('Shapiro-Wilk Test for Normality')\n",
    "stat_c, p_c = stats.shapiro(weight_data['weight'][weight_data['group'] == 'ctrl'])\n",
    "print('Ctrl group: stat=%.3f, p=%.3f' % (stat_c, p_c))\n",
    "stat_t1, p_t1 = stats.shapiro(weight_data['weight'][weight_data['group'] == 'trt1'])\n",
    "print('Trt1 group: stat=%.3f, p=%.3f' % (stat_t1, p_t1))\n",
    "stat_t2, p_t2 = stats.shapiro(weight_data['weight'][weight_data['group'] == 'trt2'])\n",
    "print('Trt2 group: stat=%.3f, p=%.3f' % (stat_t2, p_t2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shapiro wilk test suggests that **the null hypothesis may not be rejected**, i.e., that the data is normally distributed (p>0.05)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $t$-test\n",
    "\n",
    "### What is the $t$-test?\n",
    "The t-test is a statistical test used to determine if there is a significant difference between the means of two groups. The null hypothesis under consideration is that the means of two groups are the same or that there is no statistically significant difference between them [4, 10]. \n",
    "\n",
    "A t-test returns a t-value which is a measure of the difference between the means of the two groups relative to the variance of the data. For an independent t-test conducted on 2 groups of equal size, the formula for the t-value is [4]:\n",
    "\n",
    "$ t = \\frac{\\bar{X}_1-\\bar{X}_2}{s_p\\sqrt \\frac{2}{n}} $ where, \n",
    "\n",
    "$ s_p = \\sqrt \\frac{s_{X_1}^2 + s_{X_2}^2}{2} $\n",
    "\n",
    "Here, $\\bar{X}_1 $ and $\\bar{X}_2 $ are the average of group 1 and group 2, $ s_p $ is the pooled standard deviation. $s_{X_1}$ and $s_{X_2}$ are the unbiased estimators of the population variance) and n is the degrees of freedom, in this case the number of samples in the group [4].\n",
    "\n",
    "The p-value is the probability that the null hypothesis is true. A low p-value (usually less than 0.05) indicates that the null hypothesis can be rejected and that there is a statistically significant difference between the means of the datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumptions of the $t$-test [10]\n",
    "- The data is on a continuous scale.\n",
    "- The two categorical groups are independent.\n",
    "- For the independent t-test, that the observations in each group are independent, i.e., there is no relationship between them. \n",
    "- The data is normally distributed\n",
    "- There are no significant outliers\n",
    "- The variance of the two groups is equal (homogeneity of variances).\n",
    "\n",
    "It should be noted from the boxplot above that trt1 group has some outliers (lying outside $1.5 \\times IQR$ in this case). This affects the standard deviation of this group and skews the distribution as seen in the histogram plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $t$-test to compare Treatment 1 and Treatment 2\n",
    "\n",
    "An independent $t$-test to compare treatment 1 and treatment 2 is performed below. As the samples in the control and 2 treatment groups are not related to one another, then the independent $t$-test is appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the data for the treatment groups\n",
    "trt1_data = np.array(data[data['group'] == 'trt1']['weight'])\n",
    "trt2_data = np.array(data[data['group'] == 'trt2']['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An independent t-test to compare the means of trt 1 and trt 2\n",
    "stats.ttest_ind(trt1_data, trt2_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $t$-test result has a p-value of 0.0075 indicating that the null hypothesis can be rejected (there is a statistically significant difference between the means of Treatment 1 and Treatment 2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANOVA (Analysis of Variance) Test\n",
    "\n",
    "The ANOVA (Analysis of Variance) test is a statistical test developed by Ronald Fisher and is used to determine if there are statistically significant differences between the means of three or more independent groups [9]. \n",
    "\n",
    "The null hypothesis is that the means of the groups are equal or that there is no statistically significant difference between them. The ANOVA test returns an $f$-value and a $p$-value. A $p$-value below the threshold (generally <0.05) indicates that the null hypothesis can be rejected and that there is a statistically significant difference between the means of the groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumptions of the ANOVA test [12]\n",
    "\n",
    "- The data is on a continuous scale.\n",
    "- The two or more categorical groups are independent.\n",
    "- There is no relationship between the observations in each group.\n",
    "- The data is normally distributed\n",
    "- There are no significant outliers\n",
    "- The variance of the groups is equal (homogeneity of variances).\n",
    "\n",
    "Note:\n",
    "\n",
    "- From the Shapiro-Wilk test above, the null hypothesis that the data is normally distributed cannot be rejected (p>0.05).\n",
    "\n",
    "- The standard deviations of all three groups are similar with trt1 having the highest standard deviation. The dataset is deemed to satisfy the assumptions of the ANOVA test. There are tests which may be carried out to confirm this assumption\n",
    "\n",
    "- The dataset however is relatively small with only 10 samples per class - this may affect the power of the test, i.e., the ability of the test to reject the null hypothesis in the case that it is actually false (i.e., avoid a type II error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Group statistics: \\n {weight_data.groupby('group').describe()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do ANOVA test of the three groups to determine statistical significance/difference of means\n",
    "# Isolate the ctrl data\n",
    "\n",
    "ctrl_data = np.array(data[data['group'] == 'ctrl']['weight'])\n",
    "\n",
    "f, p = stats.f_oneway(ctrl_data, trt1_data, trt2_data)\n",
    "f, p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $p$-value of the ANOVA test considering the three groups is 0.015 which is below the threshold of 0.05. This would lead us to reject the null hypothesis that the means of the three groups are the same. So it is judged that there is a statistically significant difference between the means of the groups. \n",
    "\n",
    "A post-hoc test such as Tukey's HSD test may be carried out to determine which groups are significantly different from each other [5]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform post-hoc Tukey test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tukey hsd test\n",
    "# Tukey's HSD.\n",
    "res = stats.tukey_hsd(ctrl_data, trt1_data, trt2_data)\n",
    "\n",
    "# Show results\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The tukey test shows higher p-value between the control and treatment1 than between the control and treatment2, suggesting a greater effect of treatment 1 than treatment 2.  \n",
    "\n",
    "- It also indicates that there is no statistical difference between treatment 1 and treatment 2 (0.012<0.05). The inability of the test to reject the null hypothesis may be due to the larger standard deviation of treatment 1 compared to treatment 2. \n",
    "\n",
    "- So while the treatments are deemed to be statistically different from the control group, they are not statistically different from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Tests\n",
    "\n",
    "A test for the equality of variances, such as **Levene's test** (to verify the assumption that the standard deviations are equal) may be carried out to confirm the results above for the ANOVA test [7, 8]. \n",
    "\n",
    "In addition, given the existence of a control group and the assumption that the variances are equal, **Dunnett's test** may be carried out [6]. Dunnett's test is a multiple comparison test which compares the control group to the treatment groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Levene's test\n",
    "f, p = stats.levene(ctrl_data, trt1_data, trt2_data)\n",
    "print(f'Levene f-value:{f}, p-value:{p}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Levene's test would suggest that we may accept that null hypothesis that the variances are equal (p>0.05)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Dunnett test\n",
    "res = stats.dunnett(trt1_data, trt2_data, control=ctrl_data)\n",
    "print(f'Dunnett f-value:{res}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dunnett's comparison test comparing the effect of the treatments relative to the control group confirm the findings above from the ANOVA test. Both treatments show a statistically significant effect with treatment 1 being more significant that treatment 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing a Power Test\n",
    "\n",
    "The power of a test is calculated to assess the probability of detect significant different results between groups. This gives an indication of the likelihood of a type II error, i.e., that there was a significant difference but the test result implied that there was not [14].\n",
    "\n",
    "The power of a test is affected by [14]:\n",
    "\n",
    "+ the effect size (what is the difference between the groups or the difference you wish to detect)\n",
    "+ the sample size\n",
    "+ the significance level (alpha)\n",
    "\n",
    "The statsmodel package allows for a an ANOVA Power test [13]. The effect size has been calculated as the ratio of the difference between the min and max means of the 3 groups and the pooled standard deviation [15]. <br>\n",
    "\n",
    "The power of the test is calculated as 0.92 which is considered a good power level [14].\n",
    "\n",
    "This is just an indication of the power of the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the parameters for the test FTestAnovaPower\n",
    "\n",
    "# Take the mean difference as the difference between the largest and smallest means [15]\n",
    "max_mean = np.max([ctrl_data.mean(), trt2_data.mean(), trt1_data.mean()])\n",
    "min_mean = np.min([ctrl_data.mean(), trt2_data.mean(), trt1_data.mean()]) \n",
    "\n",
    "mean_diff = max_mean - min_mean\n",
    "\n",
    "# Calculate the pooled standard deviation\n",
    "pooled_std_dev = np.sqrt((ctrl_data.std()**2 + trt2_data.std()**2 + trt1_data.std()**2) / 3)\n",
    "\n",
    "n_groups = 3     # Number of groups\n",
    "n_samples = 10  # Number of samples per group\n",
    "\n",
    "# Estimate the effect size [15]\n",
    "effect_size = mean_diff / pooled_std_dev\n",
    "\n",
    "# Perform power analysis\n",
    "power_analysis = FTestAnovaPower()\n",
    "power = power_analysis.solve_power(effect_size=effect_size, nobs=n_samples, alpha=0.05, k_groups=n_groups)\n",
    "\n",
    "# Calculate the probability of Type II error (beta)\n",
    "beta = 1 - power\n",
    "\n",
    "print(f\"Power of the test: {power:.4f}\")\n",
    "print(f\"Probability of Type II error (beta): {beta:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Bundock, V. Plant Growth Dataset https://vincentarelbundock.github.io/Rdatasets/csv/datasets/PlantGrowth.csv \n",
    "2. Bundock, V. Description of the Plant Growth Dataset https://vincentarelbundock.github.io/Rdatasets/doc/datasets/PlantGrowth.html \n",
    "3. Bundock, V. Further description of the Plant Growth Dataset [Online] Available: https://vincentarelbundock.github.io/Rdatasets/ \n",
    "4. Wikipedia (2024) Student's t-test [Online] Available: https://en.wikipedia.org/wiki/Student%27s_t-test \n",
    "5. Scipy (2024) Tukey HSD test [Online]. Available: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.tukey_hsd.html#tukey-hsd\n",
    "6.  Scipy (2024) Dunnett's test [Online] Available: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.dunnett.html#dunnett\n",
    "7. Datatab Levene's test [Online]. Available: https://datatab.net/tutorial/levene-test\n",
    "8. Scipy (2024) Levene's test [Online]. Avaible: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.levene.html#levene\n",
    "9. Wikipedia (2024) Analysis of Variance. Available: https://en.wikipedia.org/wiki/Analysis_of_variance \n",
    "10. Laerd Statistics (2018). Independent t-test using SPSS Statistics [Online]. Available: https://statistics.laerd.com/spss-tutorials/independent-t-test-using-spss-statistics.php\n",
    "11. Seaborn (2024) seaborn.boxplot [Online]. Available: https://seaborn.pydata.org/generated/seaborn.boxplot.html#seaborn-boxplot\n",
    "12. Laerd Statistics (2018). One-way ANOVA in SPSS Statistics [Online]. Available: https://statistics.laerd.com/spss-tutorials/one-way-anova-using-spss-statistics.php\n",
    "13. Statsmodels (2024) ANOVA Power Test [Online] Available: https://www.statsmodels.org/stable/generated/statsmodels.stats.power.FTestAnovaPower.solve_power.html#statsmodels-stats-power-ftestanovapower-solve-power\n",
    "14. University of Cambridge. Core Statistics - Power Analysis [Online] Available: https://cambiotraining.github.io/corestats/materials/cs6_practical_power-analysis.html\n",
    "15. UCLA. One-way ANOVA Power Analysis [Online] Available: https://stats.oarc.ucla.edu/other/gpower/one-way-anova-power-analysis/#:~:text=The%20difference%20of%20the%20means,%2D550)%2F80%20%3D%201.2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
